# Shell Pipelines for Data Processing

## Introduction

In this lab, you will explore the power of shell pipelines for efficient data processing. Pipelines, often referred to as pipes, allow you to connect multiple commands, channeling the output of one command into the input of another. This technique is particularly useful when dealing with complex or large datasets. By the end of this lab, you will have a solid understanding of how to use pipelines to manipulate and analyze system information.

## Steps

### Step 1: Understanding the /proc Filesystem

The `/proc` filesystem is a virtual filesystem in Linux that provides information about the system's processes and other system information. It's called a "virtual" filesystem because it doesn't exist on disk - it's created by the Linux kernel in memory.

Let's start by examining its contents:

```bash
ls /proc
```

This command will list the contents of the `/proc` directory. You'll see numerous directories named with numbers (representing process IDs) and other special files.

Don't worry if you see a lot of output - that's normal! The `/proc` directory contains a file or directory for every process running on your system, plus additional files with system information.

#### Verification

```yaml
- name: Verify /proc listing
  script: |
    #!/bin/zsh
    grep -q "ls /proc" ~/.zsh_history
  hint: |
    Make sure you've run the command to list the contents of the /proc directory. If you haven't, type 'ls /proc' in your terminal and press Enter.
```

### Step 2: Exploring CPU Information

One of the special files in `/proc` is `cpuinfo`, which contains detailed information about the system's CPU. Let's view its contents:

```bash
cat /proc/cpuinfo
```

The `cat` command is short for "concatenate", but it's commonly used to display the contents of a file. In this case, it displays all the CPU information.

Take a moment to look through the output. You'll see details about each CPU core, including model name, clock speed, and cache size. Don't worry if you don't understand all the information - we'll focus on specific parts in the next steps.

#### Verification

```yaml
- name: Verify CPU info display
  script: |
    #!/bin/zsh
    grep -q "cat /proc/cpuinfo" ~/.zsh_history
  hint: |
    Ensure you've used the cat command to display the contents of /proc/cpuinfo. If you haven't, type 'cat /proc/cpuinfo' in your terminal and press Enter.
```

### Step 3: Introducing Pipelines

Now, let's start using pipelines to process this information. A pipeline is created using the `|` (pipe) symbol between commands. It takes the output of the command on the left and feeds it as input to the command on the right.

We'll use the `grep` command to filter the output for specific information. The `grep` command searches for patterns in text.

Let's find all lines containing "model name":

```bash
cat /proc/cpuinfo | grep "model name"
```

This pipeline first reads the contents of `/proc/cpuinfo`, then passes that output to `grep`, which filters for lines containing "model name".

You should see one line for each CPU core, showing the model of your processor(s).

#### Verification

```yaml
- name: Verify grep usage
  script: |
    #!/bin/zsh
    grep -q "grep \"model name\"" ~/.zsh_history
  hint: |
    Make sure you've used the pipeline to filter for "model name" in the CPU info. If you haven't, type 'cat /proc/cpuinfo | grep "model name"' in your terminal and press Enter.
```

### Step 4: Counting CPU Cores

To count the number of CPU cores, we can count the number of "processor" lines in the output. We'll use the `wc` (word count) command with the `-l` option to count lines:

```bash
cat /proc/cpuinfo | grep "processor" | wc -l
```

This pipeline does three things:

1. `cat /proc/cpuinfo` reads the CPU info
2. `grep "processor"` filters for lines containing "processor"
3. `wc -l` counts the number of lines in the output

The result is the number of CPU cores in your system. For example, if you see `4`, that means your system has 4 CPU cores.

#### Verification

```yaml
- name: Verify core count command
  script: |
    #!/bin/zsh
    grep -q "wc -l" ~/.zsh_history
  hint: |
    Ensure you've used the pipeline to count the number of CPU cores. If you haven't, type 'cat /proc/cpuinfo | grep "processor" | wc -l' in your terminal and press Enter.
```

### Step 5: Finding Unique CPU Models

If your system has multiple CPUs, they might be of different models. Let's find out how many unique CPU models are present:

```bash
cat /proc/cpuinfo | grep "model name" | sort | uniq | wc -l
```

This pipeline:

1. Reads the CPU info
2. Filters for "model name" lines
3. Sorts the output (which is necessary for the next step)
4. Removes duplicate lines with `uniq`
5. Counts the remaining lines

The `sort` command is necessary because `uniq` only removes adjacent duplicate lines. By sorting first, we ensure all duplicates are adjacent.

The result is the number of unique CPU models in your system. If you see `1`, it means all your CPU cores are the same model.

#### Verification

```yaml
- name: Verify unique CPU models command
  script: |
    #!/bin/zsh
    grep -q "sort | uniq" ~/.zsh_history
  hint: |
    Make sure you've used the pipeline to count unique CPU models. If you haven't, type 'cat /proc/cpuinfo | grep "model name" | sort | uniq | wc -l' in your terminal and press Enter.
```

### Step 6: Extracting CPU Clock Speed

Let's extract the CPU clock speeds:

```bash
cat /proc/cpuinfo | grep "cpu MHz" | cut -d ':' -f 2
```

This pipeline:

1. Reads the CPU info
2. Filters for "cpu MHz" lines
3. Uses `cut` to extract the part after the colon

The `cut` command is used to extract sections from each line of input. Here, `-d ':'` sets the delimiter to a colon, and `-f 2` selects the second field (everything after the colon).

The result is a list of CPU clock speeds in MHz. You might see different values if your CPU supports dynamic frequency scaling.

#### Verification

```yaml
- name: Verify clock speed extraction
  script: |
    #!/bin/zsh
    grep -q "cut -d" ~/.zsh_history
  hint: |
    Ensure you've used the pipeline to extract CPU clock speeds. If you haven't, type 'cat /proc/cpuinfo | grep "cpu MHz" | cut -d ':' -f 2' in your terminal and press Enter.
```

### Step 7: Analyzing Memory Information

Let's switch gears and look at memory information. The file `/proc/meminfo` contains details about system memory. We'll use the `head` command to view just the first few lines:

```bash
cat /proc/meminfo | head -n 5
```

This command displays the first 5 lines of memory information. The `head` command is used to output the first part of files. The `-n 5` option tells it to show the first 5 lines.

You should see information about total memory, free memory, and other memory stats.

#### Verification

```yaml
- name: Verify memory info display
  script: |
    #!/bin/zsh
    grep -q "head -n 5" ~/.zsh_history
  hint: |
    Make sure you've displayed the first 5 lines of memory information. If you haven't, type 'cat /proc/meminfo | head -n 5' in your terminal and press Enter.
```

### Step 8: Calculating Total RAM in Gigabytes

Finally, let's calculate the total RAM in gigabytes:

```bash
cat /proc/meminfo | grep "MemTotal" | awk '{print $2/1024/1024 " GB"}'
```

This pipeline:

1. Reads memory info
2. Filters for the "MemTotal" line
3. Uses `awk` to convert kilobytes to gigabytes

`awk` is a powerful text-processing tool. Here, it's doing a calculation: it takes the second field (`$2`, which is the memory in kilobytes), divides it by 1024 twice (to convert KB to MB to GB), and adds "GB" at the end.

The result is your total RAM in gigabytes. For example, if you see `7.79025 GB`, that means your system has approximately 8 GB of RAM.

#### Verification

```yaml
- name: Verify RAM calculation
  script: |
    #!/bin/zsh
    grep -q "awk '{print" ~/.zsh_history
  hint: |
    Ensure you've used the pipeline to calculate total RAM in gigabytes. If you haven't, type 'cat /proc/meminfo | grep "MemTotal" | awk '{print $2/1024/1024 " GB"}'' in your terminal and press Enter.
```

## Summary

In this lab, you explored the power of shell pipelines for data processing. You learned how to combine commands like `cat`, `grep`, `sort`, `uniq`, `wc`, `cut`, `head`, and `awk` to extract, filter, and analyze system information.

You started by exploring the `/proc` filesystem, then used various commands to analyze CPU and memory information. Along the way, you learned about important Linux commands and concepts:

- `cat` for displaying file contents
- `grep` for filtering text
- `wc` for counting
- `sort` and `uniq` for handling duplicate data
- `cut` for extracting parts of lines
- `head` for viewing the beginning of files
- `awk` for advanced text processing

These techniques are fundamental to shell scripting and can be applied to a wide range of data processing tasks in Linux systems. By mastering pipelines, you've gained a valuable tool for efficient command-line data manipulation and analysis.

Remember, practice makes perfect. Feel free to experiment with these commands on different files or combine them in new ways to solve different problems. The more you use these tools, the more comfortable and proficient you'll become with shell programming.
