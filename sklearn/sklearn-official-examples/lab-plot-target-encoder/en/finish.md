# Summary

In this lab, we compared the performance of different categorical encoders on a wine review dataset. We also looked at how to use the native categorical feature support in `HistGradientBoostingRegressor`. We found that dropping the categories perform the worst and the target encoders performs the best. The ordinal encoding imposes an arbitrary order to the features which are then treated as numerical values by the `HistGradientBoostingRegressor`. The one-hot encoding scheme would have likely made the pipeline overfitting as the number of features explodes with rare category occurrences that are correlated with the target by chance. When using the target encoder, the same binning happens, but since the encoded values are statistically ordered by marginal association with the target variable, the binning use by the `HistGradientBoostingRegressor` makes sense and leads to good results.
