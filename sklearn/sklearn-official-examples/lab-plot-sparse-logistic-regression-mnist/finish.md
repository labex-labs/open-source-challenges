# Summary

In this lab, we learned how to use logistic regression to classify hand-written digits from the MNIST dataset. We also learned how to use the SAGA algorithm with L1 penalty for logistic regression. We achieved an accuracy score of over 0.8 with a sparse weight vector, making the model more interpretable. However, we also noted that this accuracy is significantly below what can be reached by an L2-penalized linear model or a non-linear multi-layer perceptron model on this dataset.
