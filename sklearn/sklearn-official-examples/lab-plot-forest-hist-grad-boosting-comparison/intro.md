# Introduction

In this lab, we will compare the performance of two popular ensemble models, Random Forest (RF) and Histogram Gradient Boosting (HGBT), for a regression dataset in terms of score and computation time. We will vary the parameters that control the number of trees according to each estimator and plot the results to visualize the trade-off between elapsed computing time and mean test score.

> You can open the `plot-forest-hist-grad-boosting-comparison.ipynb` in WebIDE to start the exercises. Learn how to use [Jupyter Notebooks in VS Code](https://code.visualstudio.com/docs/datascience/jupyter-notebooks).
> ![](https://file.labex.io/upload/u/1991/fzLMg1oHuQrI.png)
> We can not verify your answers automatically in this lab.

