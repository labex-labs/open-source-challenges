# Summary

This lab explored the impact of uniformly-distributed random labeling on the behavior of some clustering evaluation metrics. The results indicated that non-adjusted clustering evaluation metrics can be misleading, and only adjusted measures can be safely used as a consensus index to evaluate the average stability of clustering algorithms for a given value of k on various overlapping sub-samples of the dataset.
