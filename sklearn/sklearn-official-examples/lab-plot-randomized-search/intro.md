# Introduction

In machine learning, hyperparameters are parameters that are not learned from data, but rather set prior to training. Selecting appropriate hyperparameters is crucial to achieving high accuracy in machine learning models. Two common methods for hyperparameter optimization are randomized search and grid search. In this lab, we will compare these two methods for optimizing hyperparameters of a linear Support Vector Machine (SVM) with Stochastic Gradient Descent (SGD) training.

You can open the `plot-randomized-search.ipynb` in WebIDE to start the exercises. Learn how to use [Jupyter Notebooks in VS Code](https://code.visualstudio.com/docs/datascience/jupyter-notebooks).

![](https://file.labex.io/upload/u/1991/fzLMg1oHuQrI.png)

We can not verify your answers automatically in this lab.
