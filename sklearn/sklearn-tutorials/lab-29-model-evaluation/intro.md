# Introduction

In machine learning, it is important to evaluate the quality of the predictions made by a model. This helps us understand how well the model is performing and whether it can be trusted for making accurate predictions. The scikit-learn library provides several metrics and scoring methods to quantify the quality of predictions.

In this lab, we will explore three different APIs provided by scikit-learn for model evaluation: the Estimator score method, the scoring parameter, and the metric functions.

> You can open the `29-model-evaluation.ipynb` in WebIDE to start the exercises. Learn how to use [Jupyter Notebooks in VS Code](https://code.visualstudio.com/docs/datascience/jupyter-notebooks).
> ![](https://file.labex.io/upload/u/1991/fzLMg1oHuQrI.png)
> We can not verify your answers automatically in this lab.

